{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow.keras.datasets.fashion_mnist' from 'C:\\\\Users\\\\LENOVO\\\\anaconda3\\\\envs\\\\deeplearning\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\datasets\\\\fashion_mnist\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "print(fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.datasets.fashion_mnist' from 'C:\\\\Users\\\\LENOVO\\\\anaconda3\\\\envs\\\\deeplearning\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\datasets\\\\fashion_mnist\\\\__init__.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_img, training_label), (test_img, test_label) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the index or the image that want to plot\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  [9 0 0 ... 3 0 5]\n",
      "Label :  [9 2 1 ... 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "#print label and image\n",
    "print(f'Label : ',training_label)\n",
    "print(f'Label : ', test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc318bec40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the image according the indek\n",
    "plt.imshow(training_img[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi Gambar\n",
    "- normalisasi gambar bertujuan untuk mempermudah NN untuk memperoses karena informasi pixel akan direpresentasikan pada interval 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the image train and image test\n",
    "training_img = training_img/255.0\n",
    "test_img = test_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### membuat model NN\n",
    "- model kali ini dibuat dari data sets train dan test yang bertujuan untuk mengukur seberapa akurat mesin belajar\n",
    "- beberapa syntax hyperparameter yg digunakan\n",
    "<br> Sequential -> membuat model urutan neuran\n",
    "<br> Flatter -> meratakan dimensi (mengkalikan dimensi) agar menjadi 1 dimensi\n",
    "<br> Dense -> membuat Neuron, yg akan memaksa input memiliki output sesuat dengan banyaknya neuron\n",
    "<br> Relu -> menghilangkan angka vektor negatif (non negatif model)\n",
    "![image.png](attachment:image.png)\n",
    "<br> Softmax -> menormalisasi vektor kedalam skala probabilitas 0-1 dan jumlah semua angka vektornya akan bernilai 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate the softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n",
      "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile and fit the model\n",
    "<br> The next thing to do, now that the model is defined, is to actually build it. You do this by compiling it with an optimizer and loss function as before -- and then you train it by calling model.fit() asking it to fit your training data to your training labels. It will figure out the relationship between the training data and its actual labels so in the future if you have inputs that looks like the training data, then it can predict what the label for that input is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4994 - accuracy: 0.8238\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3751 - accuracy: 0.8646\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3361 - accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3120 - accuracy: 0.8853\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc3331ee20>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer =tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "model.fit(training_img, training_label, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3573937714099884, 0.8697999715805054]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_img, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exercise 1\n",
    "<br> For this first exercise run the below code: It creates a set of classifications for each of the test images, and then prints the first entry in the classifications. The output, after you run it is a list of numbers. Why do you think this is, and what do those numbers represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2886939e-07 5.0841033e-12 9.9721861e-01 6.4682848e-10 2.6768325e-03 2.4388365e-11 1.0417961e-04 6.4131880e-14 2.8108541e-08 7.9058235e-15]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_img)\n",
    "\n",
    "print(classifications[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(test_label[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1Q1: What does this list represent?\n",
    "It's 10 random meaningless values\n",
    "It's the first 10 classifications that the computer made\n",
    "It's the probability that this item is each of the 10 classes\n",
    "Click for Answer\n",
    "#### Answer: The correct answer is (3) The output of the model is a list of 10 numbers. These numbers are a probability that the value being classified is the corresponding value (https://github.com/zalandoresearch/fashion-mnist#labels), i.e. the first value in the list is the probability that the image is of a '0' (T-shirt/top), the next is a '1' (Trouser) etc. Notice that they are all VERY LOW probabilities. For index 9 (Ankle boot), the probability was in the 90's, i.e. the neural network is telling us that the image is most likely an ankle boot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1Q2: How do you know that this list tells you that the item is an ankle boot?\n",
    "There's not enough information to answer that question\n",
    "The 10th element on the list is the biggest, and the ankle boot is labelled 9\n",
    "The ankle boot is label 9, and there are 0->9 elements in the list\n",
    "Click for Answer\n",
    "#### Answer The correct answer is (2). Both the list and the labels are 0 based, so the ankle boot having label 9 means that it is the 10th of the 10 classes. The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<br> Let's now look at the layers in your model. Experiment with different values for the dense layer with 512 neurons. What different results do you get for loss, training time etc? Why do you think that's the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1842 - accuracy: 0.9452\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0748 - accuracy: 0.9768\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0497 - accuracy: 0.9843\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0345 - accuracy: 0.9887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0273 - accuracy: 0.9908\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0701 - accuracy: 0.9804\n",
      "[2.9476157e-09 2.6594754e-10 1.0860532e-07 1.2570181e-06 6.8187280e-13 8.2277694e-08 5.1555474e-12 9.9999607e-01 1.0616796e-08 2.4755684e-06]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), # Try experimenting with this layer\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1566 sparse_categorical_crossentropy\n        return K.sparse_categorical_crossentropy(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4782 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4175 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4088 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 28, 10)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu),\n\u001b[0;32m      9\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax)])\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     18\u001b[0m classifications \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:823\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 823\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    826\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    700\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2855\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2854\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2855\u001b[0m   graph_function, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3213\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(args, kwargs)\n\u001b[0;32m   3212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3213\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, args, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3065\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3060\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3061\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3062\u001b[0m ]\n\u001b[0;32m   3063\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3064\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3076\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3077\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3078\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3079\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3081\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3082\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m--> 986\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m    991\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# We register a variable creator with reduced priority. If an outer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# variable creator is just modifying keyword arguments to the variable\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# constructor, this will work harmoniously. Since the `scope` registered\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;66;03m# better than the alternative, tracing the initialization graph but giving\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;66;03m# the user a variable type they didn't want.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:973\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    972\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 973\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    974\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1566 sparse_categorical_crossentropy\n        return K.sparse_categorical_crossentropy(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4782 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4175 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\LENOVO\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4088 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 28, 10)).\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerrcise 4\n",
    "Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5.\n",
    "\n",
    "Click for Answer\n",
    "#### Answer You get an error as soon as it finds an unexpected value. Another rule of thumb -- the number of neurons in the last layer should match the number of classes you are classifying for. In this case it's the digits 0-9, so there are 10 of them, hence you should have 10 neurons in your final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 9 which is outside the valid range of [0, 5).  Label values: 2 6 1 0 1 1 5 1 4 6 4 7 4 2 8 9 1 8 9 7 1 0 1 3 6 3 5 0 0 8 0 6\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at \\AppData\\Local\\Temp\\ipykernel_7556\\3599655500.py:14) ]] [Op:__inference_train_function_63960]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m      7\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu),\n\u001b[0;32m      8\u001b[0m                                     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax) \u001b[38;5;66;03m# Try experimenting with this layer\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                                   ])\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m     18\u001b[0m classifications \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_images)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:840\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    842\u001b[0m   canon_args, canon_kwds \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    843\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    844\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of 9 which is outside the valid range of [0, 5).  Label values: 2 6 1 0 1 1 5 1 4 6 4 7 4 2 8 9 1 8 9 7 1 0 1 3 6 3 5 0 0 8 0 6\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at \\AppData\\Local\\Temp\\ipykernel_7556\\3599655500.py:14) ]] [Op:__inference_train_function_63960]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax) # Try experimenting with this layer\n",
    "                                  ])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5:\n",
    "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10.\n",
    "\n",
    "Click for Answer\n",
    "#### Answer There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1861\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0802\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0543\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0420\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0320\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0896\n",
      "[5.5850441e-10 1.9453144e-07 5.4822726e-06 1.1784378e-03 3.8119509e-08 5.2843710e-08 2.7928032e-10 9.9850285e-01 7.6575304e-07 3.1221859e-04]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation = tf.nn.relu),# Add a layer here,\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)# Add a layer here\n",
    "                                  ])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "E6Q1: Consider the impact of training for more or less epochs. Why do you think that would be the case?\n",
    "Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
    "Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases.\n",
    "This is a side effect of something called 'overfitting' which you can learn about later and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2558\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1125\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0778\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0581\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0448\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0358\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0282\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0234\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0155\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0802\n",
      "[2.89537545e-13 3.59135299e-09 1.01039326e-07 2.17422084e-07 9.75955703e-16 1.70071277e-15 3.00840353e-15 9.99999642e-01 9.35845956e-10 1.77305497e-11]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10) # Experiment with the number of epochs\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[34])\n",
    "print(test_labels[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc38fbf070>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7:\n",
    "Before you trained, you normalized the data, going from values that were 0-255 to values that were 0-1. What would be the impact of removing that? Here's the complete code to give it a try. Why do you think you get different results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 2.5388\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3521\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3209\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2591\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3532\n",
      "[0.0000000e+00 0.0000000e+00 2.8089357e-24 5.2168956e-20 7.6090595e-36 1.1124142e-31 0.0000000e+00 1.0000000e+00 0.0000000e+00 2.3519904e-24]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#training_images=training_images/255.0 # Experiment with removing this line\n",
    "#test_images=test_images/255.0 # Experiment with removing this line\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8:\n",
    "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.8310 ETA: 0s - loss: 0.4767 - accura\n",
      "Reached 60% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4738 - accuracy: 0.8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc33308e50>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy') >= 0.6): # Experiment with changing this value\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3863 - accuracy: 0.8631\n",
      "[1.0412363e-05 1.0086576e-06 1.5601023e-05 9.0320036e-06 6.1776104e-06 3.7533402e-02 1.9750829e-05 1.4348350e-01 1.0570189e-03 8.1786412e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
